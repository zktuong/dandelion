{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zktuong/dandelion/blob/master/container/dandelion_singularity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RX_Q1Ynbfz-"
   },
   "source": [
    "# Introduction to `dandelion`\n",
    "<img src='https://github.com/zktuong/dandelion/blob/master/docs/notebooks/img/dandelion_logo_illustration.png?raw=true'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhafogmrHg5H"
   },
   "source": [
    "Welcome to the Google Colab notebook example/tutorial for Dandelion! In this notebook, we will run through an example workflow for 1) pre-processing, 2) post-processing and 3) pseudobulk V(D)J trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwkDT2N3rvAo"
   },
   "source": [
    "## Preprocessing - V(D)J reannotation\n",
    "\n",
    "We will try out the full reannotation workflow in this part of the colab notebook. To do that, we need to set up the other non-python dependencies. This is normally taken care of by the [singularity container](https://sc-dandelion.readthedocs.io/en/latest/notebooks/Q1-singularity-preprocessing.html) but it's very difficult to set it up on Google Colab architecture, so we will continue manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jsHAhD9uvwV",
    "outputId": "2dc958dc-52f9-420c-a375-489a1395a3de"
   },
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "# Run this block by itself first.\n",
    "# This will lead to a kernel restart, so don't be alarm by the session crashing.\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hg-CU5SJ5W0Y",
    "outputId": "f16a0556-e936-4e2e-a547-b6d7a2f11019"
   },
   "outputs": [],
   "source": [
    "# download reannotation dependencies\n",
    "!mamba install -y -qq -c bioconda -c conda-forge igblast blast r-optparse r-alakazam r-tigger r-airr r-shazam\n",
    "# obtain the reference databases\n",
    "!git clone -q https://github.com/zktuong/dandelion.git\n",
    "# set paths to databases\n",
    "import os\n",
    "os.environ[\"IGDATA\"] = \"/content/dandelion/container/database/igblast/\"\n",
    "os.environ[\"GERMLINE\"] = \"/content/dandelion/container/database/germlines/\"\n",
    "os.environ[\"BLASTDB\"] = \"/content/dandelion/container/database/blast/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cz_yEFkJQ6xk",
    "outputId": "a84cc552-b46a-47da-ad6f-cef9e36ab726"
   },
   "outputs": [],
   "source": [
    "# install dandelion and scanpy\n",
    "!pip install -q sc-dandelion scanpy[leiden] networkx==2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGxP8-UOQ63P",
    "outputId": "648e6660-f8e7-49cc-d218-25d21e2a2fc0"
   },
   "outputs": [],
   "source": [
    "# import and show versions\n",
    "import dandelion as ddl\n",
    "\n",
    "ddl.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8eQnXggICzi"
   },
   "source": [
    "### Download example datasets from 10X\n",
    "\n",
    "We will download example datasets freely available from 10X Genomics. To keep this part of the tutorial short, we will trim to just 1000 contigs in the files in the second block but definitely do try it again later on the full datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58iS20Iw9WgO",
    "outputId": "26f45495-d81e-4d7a-ee7b-4172f0bfea15"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "if [ ! -d \"/content/dandelion_tutorial/vdj_v1_hs_pbmc3\" ]; then mkdir -p /content/dandelion_tutorial/vdj_v1_hs_pbmc3; fi\n",
    "# cd /content/dandelion_tutorial/vdj_v1_hs_pbmc3 && wget -q -O filtered_feature_bc_matrix.h5 https://cf.10xgenomics.com/samples/cell-vdj/3.1.0/vdj_v1_hs_pbmc3/vdj_v1_hs_pbmc3_filtered_feature_bc_matrix.h5;\n",
    "cd /content/dandelion_tutorial/vdj_v1_hs_pbmc3 && wget -q -O filtered_contig_annotations.csv https://cf.10xgenomics.com/samples/cell-vdj/3.1.0/vdj_v1_hs_pbmc3/vdj_v1_hs_pbmc3_b_filtered_contig_annotations.csv;\n",
    "cd /content/dandelion_tutorial/vdj_v1_hs_pbmc3 && wget -q -O filtered_contig.fasta https://cf.10xgenomics.com/samples/cell-vdj/3.1.0/vdj_v1_hs_pbmc3/vdj_v1_hs_pbmc3_b_filtered_contig.fasta;\n",
    "\n",
    "if [ ! -d \"/content/dandelion_tutorial/vdj_nextgem_hs_pbmc3\" ]; then mkdir -p /content/dandelion_tutorial/vdj_nextgem_hs_pbmc3; fi\n",
    "# cd /content/dandelion_tutorial/vdj_nextgem_hs_pbmc3 && wget -q -O filtered_feature_bc_matrix.h5 https://cf.10xgenomics.com/samples/cell-vdj/3.1.0/vdj_nextgem_hs_pbmc3/vdj_nextgem_hs_pbmc3_filtered_feature_bc_matrix.h5;\n",
    "cd /content/dandelion_tutorial/vdj_nextgem_hs_pbmc3 && wget -q -O filtered_contig_annotations.csv https://cf.10xgenomics.com/samples/cell-vdj/3.1.0/vdj_nextgem_hs_pbmc3/vdj_nextgem_hs_pbmc3_b_filtered_contig_annotations.csv;\n",
    "cd /content/dandelion_tutorial/vdj_nextgem_hs_pbmc3 && wget -q -O filtered_contig.fasta https://cf.10xgenomics.com/samples/cell-vdj/3.1.0/vdj_nextgem_hs_pbmc3/vdj_nextgem_hs_pbmc3_b_filtered_contig.fasta;\n",
    "\n",
    "if [ ! -d \"/content/dandelion_tutorial/sc5p_v2_hs_PBMC_10k\" ]; then mkdir -p /content/dandelion_tutorial/sc5p_v2_hs_PBMC_10k; fi\n",
    "# cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_10k && wget -q -O filtered_feature_bc_matrix.h5 https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_filtered_feature_bc_matrix.h5;\n",
    "cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_10k && wget -q -O filtered_contig_annotations.csv https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_b_filtered_contig_annotations.csv;\n",
    "cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_10k && wget -q -O filtered_contig.fasta https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_b_filtered_contig.fasta;\n",
    "\n",
    "if [ ! -d \"/content/dandelion_tutorial/sc5p_v2_hs_PBMC_1k\" ]; then mkdir -p /content/dandelion_tutorial/sc5p_v2_hs_PBMC_1k; fi\n",
    "# cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_1k && wget -q -O filtered_feature_bc_matrix.h5 wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_1k/sc5p_v2_hs_PBMC_1k_filtered_feature_bc_matrix.h5;\n",
    "cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_1k && wget -q -O filtered_contig_annotations.csv wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_1k/sc5p_v2_hs_PBMC_1k_b_filtered_contig_annotations.csv;\n",
    "cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_1k && wget -q -O filtered_contig.fasta https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_1k/sc5p_v2_hs_PBMC_1k_b_filtered_contig.fasta;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dmys4I_RJAOa",
    "outputId": "3da59d28-ff3a-414b-bade-c3b0f6a260fa"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "# trim to just 1000 contigs to make this part of the tutorial shorter\n",
    "cd /content/dandelion_tutorial/vdj_v1_hs_pbmc3 && head -1000 filtered_contig.fasta > filtered_1k_contig.fasta && sed -i '1,+999d' filtered_contig.fasta && head -1001 filtered_contig_annotations.csv > filtered_1k_contig_annotations.csv && sed -i '1,+1000d' filtered_contig_annotations.csv\n",
    "cd /content/dandelion_tutorial/vdj_nextgem_hs_pbmc3 && head -1000 filtered_contig.fasta > filtered_1k_contig.fasta && sed -i '1,+999d' filtered_contig.fasta && head -1001 filtered_contig_annotations.csv > filtered_1k_contig_annotations.csv && sed -i '1,+1000d' filtered_contig_annotations.csv\n",
    "cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_10k && head -1000 filtered_contig.fasta > filtered_1k_contig.fasta && sed -i '1,+999d' filtered_contig.fasta && head -1001 filtered_contig_annotations.csv > filtered_1k_contig_annotations.csv && sed -i '1,+1000d' filtered_contig_annotations.csv\n",
    "cd /content/dandelion_tutorial/sc5p_v2_hs_PBMC_1k && head -1000 filtered_contig.fasta > filtered_1k_contig.fasta && sed -i '1,+999d' filtered_contig.fasta && head -1001 filtered_contig_annotations.csv > filtered_1k_contig_annotations.csv && sed -i '1,+1000d' filtered_contig_annotations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVduiOVQIPwV"
   },
   "source": [
    "## Preprocessing 10X data\n",
    "\n",
    "Just like the [original tutorial](https://sc-dandelion.readthedocs.io/en/latest/notebooks/1_dandelion_preprocessing-10x_data.html), we will format the files, reannotate with `igblastn`, reassign the V gene alleles, assign the isotype calls and quantify mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaFeH6e-sceo"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/dandelion_tutorial\")\n",
    "samples = [\n",
    "    \"sc5p_v2_hs_PBMC_1k\",\n",
    "    \"sc5p_v2_hs_PBMC_10k\",\n",
    "    \"vdj_v1_hs_pbmc3\",\n",
    "    \"vdj_nextgem_hs_pbmc3\",\n",
    "]\n",
    "filename_prefixes = [\"filtered_1k\" for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEPKQLhGBzP7",
    "outputId": "5af4e32d-b018-408f-b2d9-4099396ce49a"
   },
   "outputs": [],
   "source": [
    "ddl.pp.format_fastas(samples, prefix=samples, filename_prefix=filename_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5V6dGeYDtaNM",
    "outputId": "e8691dc0-f5ce-4c6c-d892-0412d29ed26a"
   },
   "outputs": [],
   "source": [
    "ddl.pp.reannotate_genes(samples, filename_prefix=filename_prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "xs_mO1KPtaWi",
    "outputId": "e6960391-252b-4cba-9118-3fc590906db2"
   },
   "outputs": [],
   "source": [
    "# reassigning alleles on the first set of samples\n",
    "ddl.pp.reassign_alleles(\n",
    "    samples[:2],\n",
    "    combined_folder=\"tutorial_scgp1\",\n",
    "    filename_prefix=filename_prefixes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "v-HzfGUVIVww",
    "outputId": "2e7a27ad-0def-4585-a9e5-a10ac2af2ad4"
   },
   "outputs": [],
   "source": [
    "# reassigning alleles on the second set of samples\n",
    "ddl.pp.reassign_alleles(\n",
    "    samples[2:],\n",
    "    combined_folder=\"tutorial_scgp2\",\n",
    "    filename_prefix=filename_prefixes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r2XPFiiqA-T5",
    "outputId": "1a25e0ab-1495-4914-88e0-95a71eda35ba"
   },
   "outputs": [],
   "source": [
    "ddl.pp.assign_isotypes(samples, filename_prefix=filename_prefixes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QTw9GHpIfpu",
    "outputId": "2cb74769-5805-4e3b-db5d-e5dd32880b05"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# quantify mutations\n",
    "for s in tqdm(samples, desc=\"Basic mutational load analysis \"):\n",
    "    filePath = s + \"/dandelion/filtered_1k_contig_dandelion.tsv\"\n",
    "    ddl.pp.quantify_mutations(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6ImfnLZOBtF"
   },
   "source": [
    "And now we have a processed output (`filtered_1k_contig_dandelion.tsv`) in each folder that can be used for downstream exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNAZ6p9xXJlz"
   },
   "source": [
    "# Post-processing - V(D)J analysis\n",
    "\n",
    "We will now switch to the post-processing tutorial. Let's follow the rest of the [original tutorial](https://sc-dandelion.readthedocs.io/en/latest/notebooks/Q2-analysis.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkSDBTzoK2a4",
    "outputId": "791b5141-0143-4e04-a157-1687741d024b"
   },
   "outputs": [],
   "source": [
    "import dandelion as ddl\n",
    "import scanpy as sc\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ddl.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlDBNbthPJ9U",
    "outputId": "56f7bcca-154b-401b-fe2f-7ac462047b18"
   },
   "outputs": [],
   "source": [
    "sc.logging.print_header()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tN8HVKYSW6UW"
   },
   "source": [
    "Let’s run through some of what `Dandelion` can do in terms of analysis. In order to kickstart this tutorial, we prepared GEX and V(D)J objects with four demo 10X samples parsed for your convenience. You can download them from the ftp site as per below. The GEX has had some basic `Scanpy` analysis performed on it, all the way up to making a UMAP and calling Leiden clusters. The VDJ is just four calls of `ddl.read_10x_airr()`, with the individual objects saved to a list, which was then passed to `ddl.concat()` to get a combined `Dandelion` object. No analysis was done on this combined object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wTRvGdn-WHjo"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"demo-gex.h5ad\"):\n",
    "    os.system(\"wget ftp://ftp.sanger.ac.uk/pub/users/kp9/demo-gex.h5ad\")\n",
    "\n",
    "if not os.path.exists(\"demo-vdj.h5ddl\"):\n",
    "    os.system(\"wget ftp://ftp.sanger.ac.uk/pub/users/kp9/demo-vdj.h5ddl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyuErJEFh8gz"
   },
   "source": [
    "Let’s import the objects. `Dandelion`’s h5ddl files can be read via `ddl.read_h5ddl()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMUcP_d_WEzK"
   },
   "outputs": [],
   "source": [
    "adata = sc.read(\"demo-gex.h5ad\")\n",
    "vdj = ddl.read_h5ddl(\"demo-vdj.h5ddl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46HsovjbU2By"
   },
   "source": [
    "At this point you’re probably wondering why there’s a separate Dandelion object. The reason is AIRR compliance. Some of the AIRR columns have more complex typing than what Scanpy can currently support within its objects. However, it’s quite straightforward to link up a Scanpy object with a `Dandelion` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoU2v0eVU0Y7",
    "outputId": "35395ecd-47c9-4211-e500-6c791eb99cde"
   },
   "outputs": [],
   "source": [
    "vdj, adata = ddl.pp.check_contigs(vdj, adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eXPgvxdXkyf"
   },
   "source": [
    "This filters the contigs and synchronises relevant information between the objects. Once linked up like this, any new information can be copied over from the Dandelion object via `ddl.tl.transfer()`.\n",
    "\n",
    "For now, let’s take a look at the chain status (as gotten from the Dandelion object) and known BCR marker expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "HQMHWnkg2UGL",
    "outputId": "443b10d4-5e4a-47db-f968-3b79781b2d21"
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"IGHM\", \"JCHAIN\", \"chain_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOQW4VpX2tFV"
   },
   "source": [
    "Under the hood, the `Dandelion` object is essentially two data frames. .data holds the AIRR-compliant contig space table, while `.metadata` is an `.obs` equivalent that parses the contig information to a cell level and can be easily integrated with a `Scanpy` object. There are also `ddl.to_scirpy()` and `ddl.from_scirpy()` for interoperability with `Scirpy`, as explored in a notebook in the extended tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3dY6p00N1ye",
    "outputId": "00082e85-52b5-4c05-8571-4a11f2374cf1"
   },
   "outputs": [],
   "source": [
    "vdj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_Lij5Bo3Cld"
   },
   "source": [
    "Now that we’ve got the gist of basic handling of the `Dandelion` object, let’s use it for some analysis!\n",
    "\n",
    "A core element of V(D)J analysis is clonotype calling, roughly equivalent to clustering cells in GEX processing. `Dandelion` requires the clones it calls to have identical V and J genes, along with no more than 15% mismatches in the CDR3 sequences (common practice in BCR analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCw7rLXrnD0Z",
    "outputId": "d7ce86f1-7269-4c61-ff07-b49e9520ce71"
   },
   "outputs": [],
   "source": [
    "ddl.tl.find_clones(vdj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK1JosNE3Kls"
   },
   "source": [
    "We can compute a graph based on Levenshtein distance of the complete contig sequence. A NetworkX representation of it is now saved in `vdj.graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqAeAKSN3JiQ",
    "outputId": "29c2702d-f991-43fd-be76-b3bd2ed9e0d1"
   },
   "outputs": [],
   "source": [
    "ddl.tl.generate_network(vdj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy3X_lX9KKcQ"
   },
   "source": [
    "`graph-tool` is very difficult to install on Google Colab so we will skip that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgB-ZC7Y3Psh"
   },
   "source": [
    "Since we now know what our clonotype calls are, we can quantify clonal expansion. It’s possible to cap this at a desired maximum clonotype size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeSGf90LnLUd"
   },
   "outputs": [],
   "source": [
    "ddl.tl.clone_size(vdj)\n",
    "ddl.tl.clone_size(vdj, max_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD0G3liQ3UVJ"
   },
   "source": [
    "Now that our Dandelion object has analysis information inside it, we can copy it over to the Scanpy object to have access to it there. The graph gets turned into the Scanpy standard forms of `.obsp['vdj_distances']` and `.obsp['vdj_connectivites']` for potential downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUrLjy04nbFz"
   },
   "outputs": [],
   "source": [
    "ddl.tl.transfer(adata, vdj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_B35QnvXy39"
   },
   "source": [
    "Let’s take a look at what we made!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "4OV8SP6AR4au",
    "outputId": "da10f4af-2277-40c4-f8c7-3447562cc0a8"
   },
   "outputs": [],
   "source": [
    "ddl.pl.clone_network(adata, color=\"clone_id_size\")\n",
    "sc.pl.umap(adata, color=\"clone_id_size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlkATIpUiXnZ"
   },
   "source": [
    "Wait, why are we seeing some clone size 0 in the plots? Orphan chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "baPw1Q2AcLYg",
    "outputId": "ea2b950d-0427-4e96-b6db-d5cad40c3025"
   },
   "outputs": [],
   "source": [
    "ddl.pl.clone_network(adata, color=\"clone_id_size_max_3\", na_in_legend=False)\n",
    "sc.pl.umap(adata, color=\"clone_id_size_max_3\", na_in_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIkWUY3EX9PS"
   },
   "source": [
    "Dandelion comes with a number of plotting functions for your convenience. However, those functions tend to operate best without the Scanpy plotting defaults in place. You can reset Matplotlib’s configuration prior to using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yT_vmx9kX-hJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ImsEJcaYSrF"
   },
   "source": [
    "We’ve got bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "MwcqDTH1YQOs",
    "outputId": "8b89d9fc-ba9f-4752-8538-6cb79ba4aa19"
   },
   "outputs": [],
   "source": [
    "ddl.pl.barplot(\n",
    "    vdj[vdj.metadata.isotype_status != \"Multi\"],  # remove multi from the plots\n",
    "    color=\"v_call_genotyped_VDJ\",\n",
    "    xtick_fontsize=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3wv3O7kYTMi"
   },
   "source": [
    "All of the plotting functions have a number of parameters that can be fiddled with for desired visualisation outcomes. For example, let’s disable automatic descending sorting, show counts rather than proportions, and change the palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "WH0T6L1AYQRl",
    "outputId": "fe31eb79-31eb-49e0-b9ec-a87d3cfaeddf"
   },
   "outputs": [],
   "source": [
    "ddl.pl.barplot(\n",
    "    vdj[vdj.metadata.isotype_status != \"Multi\"],\n",
    "    color=\"v_call_genotyped_VDJ\",\n",
    "    normalize=False,\n",
    "    sort_descending=None,\n",
    "    palette=\"tab20\",\n",
    "    xtick_fontsize=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFPBE40tEKJ1"
   },
   "source": [
    "We’ve got stacked bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "w9MbtURuYQVF",
    "outputId": "9fd4fb13-a569-4c10-90c8-2239cb33ed8e"
   },
   "outputs": [],
   "source": [
    "ddl.pl.stackedbarplot(\n",
    "    vdj[vdj.metadata.isotype_status != \"Multi\"],\n",
    "    color=\"isotype_status\",\n",
    "    groupby=\"locus_status\",\n",
    "    xtick_rotation=0,\n",
    "    figsize=(4, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIurpDpTgtBf"
   },
   "source": [
    "These can be normalised to add up to 1 for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "iV5_OOTpY44h",
    "outputId": "4489359e-917d-4a49-ebd7-c6b0424dbb0f"
   },
   "outputs": [],
   "source": [
    "ddl.pl.stackedbarplot(\n",
    "    vdj[vdj.metadata.isotype_status != \"Multi\"],\n",
    "    color=\"v_call_genotyped_VDJ\",\n",
    "    groupby=\"isotype_status\",\n",
    "    normalize=True,\n",
    "    xtick_fontsize=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glAQ7It1EU-R"
   },
   "source": [
    "We’ve also got a spectratype plot, which shows the distribution of the CDR3 length for the various contigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "-WoVtLCREbAj",
    "outputId": "75681e56-ecb5-4255-d9cf-9ec97045ba0a"
   },
   "outputs": [],
   "source": [
    "ddl.pl.spectratype(\n",
    "    vdj[vdj.metadata.isotype_status != \"Multi\"],\n",
    "    color=\"junction_length\",\n",
    "    groupby=\"c_call\",\n",
    "    locus=\"IGH\",\n",
    "    width=2.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4iFJjaNEVCK"
   },
   "source": [
    "Another common V(D)J analysis request is to examine the distribution of shared clonotypes between cells of different metadata groups. Dandelion can do this as a circos plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "nnfQqWJNEfsq",
    "outputId": "6e5b5084-32bb-4103-da54-be0300d43d95"
   },
   "outputs": [],
   "source": [
    "ddl.tl.clone_overlap(adata, groupby=\"leiden\", weighted_overlap=True)\n",
    "ddl.pl.clone_overlap(adata, groupby=\"leiden\", weighted_overlap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TGR2c6tEVFV"
   },
   "source": [
    "There’s also a heatmap on offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "HspVilSCEkLs",
    "outputId": "ca320ef0-b558-4edf-b222-1145df45cb93"
   },
   "outputs": [],
   "source": [
    "ddl.pl.clone_overlap(\n",
    "    adata,\n",
    "    groupby=\"leiden\",\n",
    "    weighted_overlap=True,\n",
    "    as_heatmap=True,\n",
    "    # seaborn clustermap kwargs\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    figsize=(8, 8),\n",
    "    annot_kws={\"size\": 10},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxrIoSuMEkjL"
   },
   "source": [
    "Save the objects, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5brCZFMVEkuR"
   },
   "outputs": [],
   "source": [
    "adata.write(\"demo-gex-processed.h5ad\")\n",
    "vdj.write(\"demo-vdj-processed.h5ddl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_fZB53bFHPV"
   },
   "source": [
    "# V(D)J pseudobulk feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SybrcuYFBoJ"
   },
   "outputs": [],
   "source": [
    "import dandelion as ddl\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKZdouVYFMtY"
   },
   "source": [
    "This notebook makes use of `Milopy` and `Palantir`, two packages that are not formally `Dandelion`’s dependencies. V(D)J feature space applications are open-ended, this is just one of them. Be sure to install the packages beforehand if you want to follow along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRuRVR0-FK1B",
    "outputId": "9251cb8e-5e60-4309-a335-2a28f16b488f"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/emdann/milopy.git palantir -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVFMjEqpFK4A",
    "outputId": "934ff429-8db9-4236-9362-09fdaf1910d3"
   },
   "outputs": [],
   "source": [
    "import milopy.core as milo\n",
    "import palantir\n",
    "\n",
    "#required because of Palantir\n",
    "%matplotlib inline\n",
    "\n",
    "sc.settings.set_figure_params(dpi=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e81u5-CJGB-g"
   },
   "source": [
    "We’ve prepared a demo object based on the TCR trajectory shown in the manuscript for you to use here. It’s had some analysis done on the GEX, and has Dandelion-derived contig information merged into it. You can download it from the ftp site as per below.\n",
    "\n",
    "It’s possible to use V(D)J information that comes from other sources than Dandelion processing, e.g. the pseudobulking will work with Scirpy output. The functions are just calibrated to work with Dandelion’s structure by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4UecCPDFK6h"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"demo-pseudobulk.h5ad\"):\n",
    "    os.system(\"wget ftp://ftp.sanger.ac.uk/pub/users/kp9/demo-pseudobulk.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg8GfVg_GIYG"
   },
   "source": [
    "Prior to performing the pseudobulking, it is recommended to run `ddl.tl.setup_vdj_pseudobulk()`. This will subset the object to just cells with paired chains, and prepare appropriately named and formatted columns for the pseudobulking function to use as defaults.\n",
    "\n",
    "If working with non-Dandelion V(D)J processing, subset your cells to ones with at least a full pair of chains, and ensure that you have four columns in place which contain the V(D)J calls for both of the identified primary chains. Scirpy stores this information natively.\n",
    "\n",
    "If you are wanting to include D calls (disabled by default), the recommendation is to subset to only cells/contigs with d_call annotated otherwise the separation could be unreliable (due to missing d_call because of technical reasons rather than biology). Please look at the options for `ddl.tl.setup_vdj_pseudobulk()` carefully to tailor to your use case.\n",
    "\n",
    "We will proceed with the default settings, which is to only consider the primary V and J calls (productive and highest UMI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGMm7np5FK92"
   },
   "outputs": [],
   "source": [
    "adata = sc.read(\"demo-pseudobulk.h5ad\")\n",
    "adata = ddl.tl.setup_vdj_pseudobulk(adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpxxm9f1GTMF"
   },
   "source": [
    "We’re going to be using Milopy to create pseudobulks. Construct a neighbour graph with many neighbours, following Milopy protocol, and then sample representative neighbourhoods from the object. This saves a cell-by-pseudobulk matrix into `adata.obsm[\"nhoods\"]`. Use this graph to generate a UMAP as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKUiMuUYGTZe"
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep=\"X_scvi\", n_neighbors=50)\n",
    "milo.make_nhoods(adata)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mJVMkhGGt_h"
   },
   "source": [
    "Now we are armed with everything we need to construct the V(D)J feature space. Pseudobulks can be defined either via passing a list of `.obs` metadata columns, the unique values of the combination of which will serve as individual pseudobulks (via `obs_to_bulk`), or via an explicit cell-by-pseudobulk matrix (via `pbs`). Milopy created one of those for us, so we can use that as input.\n",
    "\n",
    "The cell type annotation lives in `.obs[\"anno_lvl_2_final_clean\"]`. Let’s tell the function that we want to take the most common value per pseudobulk with us to the new V(D)J feature space object.\n",
    "\n",
    "For non-Dandelion V(D)J processing, use the cols argument to specify which .obs columns contain the V(D)J calls for the identified primary chains. For Scirpy, this would mean specifying e.g. `cols = ['IR_VDJ_1_v_gene', 'IR_VDJ_1_j_gene', 'IR_VJ_1_v_gene', 'IR_VJ_1_j_gene']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvZhzIdyGTcz"
   },
   "outputs": [],
   "source": [
    "pb_adata = ddl.tl.vdj_pseudobulk(\n",
    "    adata, pbs=adata.obsm[\"nhoods\"], obs_to_take=\"anno_lvl_2_final_clean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa1W6RJ4G3A8"
   },
   "source": [
    "The new object has pseudobulks as observations, and the unique encountered V(D)J genes as the features. We can see the per-pseudobulk annotation, and `.uns[\"pseudobulk_assigments\"]`. In our case it’s just a copy of the `pbs` argument, but if we were to go for `obs_to_bulk` this would be a cells by pseudobulks matrix capturing the assignment of the original cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5ZRQqGMGTjL",
    "outputId": "604aa793-bfed-48ac-ebbf-27d72c1a8b48"
   },
   "outputs": [],
   "source": [
    "pb_adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40pcTAZSG-0V"
   },
   "source": [
    "Now that we have our V(D)J feature space pseudobulk object, we can do things with it. Let’s run a PCA on it. The development trajectory is very nicely captured in the first two PC dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TtXdIuZsGTnF",
    "outputId": "f34ed32a-ab44-4294-d635-355a2c5dbf79"
   },
   "outputs": [],
   "source": [
    "sc.tl.pca(pb_adata)\n",
    "sc.pl.pca(pb_adata, color=\"anno_lvl_2_final_clean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Tk9KcUrHCUg"
   },
   "source": [
    "Let’s define the start of our trajectory as the right-most cell, the CD4 terminal state as the bottom-most cell, and the CD8 terminal state as the top-most cell. We can then follow Palantir protocol to generate a diffusion map and run pseudotime. Once done, we rename the terminal states to be more informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EfCuff9HCpY",
    "outputId": "45019520-2d39-4e66-8913-9ba2efd2a58b"
   },
   "outputs": [],
   "source": [
    "rootcell = np.argmax(pb_adata.obsm[\"X_pca\"][:, 0])\n",
    "terminal_states = pd.Series(\n",
    "    [\"CD8+T\", \"CD4+T\"],\n",
    "    index=pb_adata.obs_names[\n",
    "        [\n",
    "            np.argmax(pb_adata.obsm[\"X_pca\"][:, 1]),\n",
    "            np.argmin(pb_adata.obsm[\"X_pca\"][:, 1]),\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Run diffusion maps\n",
    "pca_projections = pd.DataFrame(pb_adata.obsm[\"X_pca\"], index=pb_adata.obs_names)\n",
    "dm_res = palantir.utils.run_diffusion_maps(pca_projections, n_components=5)\n",
    "ms_data = palantir.utils.determine_multiscale_space(dm_res)\n",
    "\n",
    "pr_res = palantir.core.run_palantir(\n",
    "    ms_data,\n",
    "    pb_adata.obs_names[rootcell],\n",
    "    num_waypoints=500,\n",
    "    terminal_states=terminal_states.index,\n",
    ")\n",
    "\n",
    "pr_res.branch_probs.columns = terminal_states[pr_res.branch_probs.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1bfDgXOHCzx"
   },
   "source": [
    "We can easily transfer the inferred pseudotime and branching probabilities to the pseudobulk object with the aid of a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qlZ5uJvdHC9a",
    "outputId": "b8bcb518-f663-4321-9d48-1b0609e9db18"
   },
   "outputs": [],
   "source": [
    "pb_adata = ddl.tl.pseudotime_transfer(pb_adata, pr_res)\n",
    "sc.pl.pca(\n",
    "    pb_adata,\n",
    "    color=[\"pseudotime\", \"prob_CD4+T\", \"prob_CD8+T\"],\n",
    "    color_map=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV3mXo3rHN15"
   },
   "source": [
    "We can project back our findings to the original cell space object via another helper function. This will remove any cells not in any of the pseudobulks. In the event of a cell belonging to multiple pseudobulks, the cell’s pseudotime will be the average of the pseudobulks weighted by the inverse of the pseudobulk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lJO3DqIAHOBA",
    "outputId": "75b3b607-467e-4a0e-8e3f-e6cfc3440724"
   },
   "outputs": [],
   "source": [
    "bdata = ddl.tl.project_pseudotime_to_cell(\n",
    "    adata, pb_adata, terminal_states.values\n",
    ")\n",
    "sc.pl.umap(bdata, color=[\"anno_lvl_2_final_clean\"])\n",
    "sc.pl.umap(\n",
    "    bdata,\n",
    "    color=[\"pseudotime\", \"prob_CD4+T\", \"prob_CD8+T\"],\n",
    "    color_map=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ00rIt-EVH1"
   },
   "source": [
    "For more in-depth tutorial and examples of the workflow, please visit `dandelion`'s [documentation](https://sc-dandelion.readthedocs.io/) and [github repository](https://github.com/zktuong/dandelion)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "dandelion_singularity.ipynb",
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
