{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dandelion preprocessing with Singularity\n",
    "\n",
    "![dandelion_logo](img/dandelion_logo_illustration.png)\n",
    "\n",
    "Arguably the greatest strength of the dandelion package is a streamlined preprocessing setup making use of a variety of specialised single cell VDJ algorithms:\n",
    "\n",
    "- V(D)J gene reannotation with [changeo's](https://changeo.readthedocs.io/en/stable/examples/10x.html) `AssignGenes.py` and `MakeDB.py`\n",
    "- Reassigning heavy chain IG V gene alleles with [TIgGER](https://tigger.readthedocs.io/en/stable/)\n",
    "- Reassigning IG constant region calls by blasting against a curated set of highly specific C gene sequences\n",
    "\n",
    "However, running this workflow requires a high number of dependencies and databases, which can be troublesome to set up. As such, we've put together a Singularity container that comes pre-configured with all of the required software and resources, allowing you to run the pre-processing pipeline with a single call and easy installation.\n",
    "\n",
    "## Setup and running\n",
    "\n",
    "Once you have [Singularity installed](https://sylabs.io/guides/3.0/user-guide/installation.html), you can download the Dandelion container. This command will create `sc-dandelion_latest.sif`, note its location.\n",
    "\n",
    "    singularity pull library://kt16/default/sc-dandelion:latest\n",
    "\n",
    "In order to prepare your BCR data for ingestion, create a folder for each sample you'd like to analyse, name it with your sample ID, and store the Cell Ranger `filtered_contig_annotations.csv` and `filtered_contig.fasta` output files inside.\n",
    "\n",
    "    5841STDY7998693\n",
    "    ├── filtered_contig_annotations.csv\n",
    "    └── filtered_contig.fasta\n",
    "\n",
    "You can then navigate to the directory holding all your sample folders and run Dandelion pre-processing like so:\n",
    "\n",
    "    singularity run -B $PWD /path/to/sc-dandelion_latest.sif dandelion-preprocess [optional arguments follow here]\n",
    "\n",
    "If you're running TR data rather than IG data, specify `--chain TR`. If you wish to process files that have a different prefix than `filtered`, e.g. `all_contig_annotations.csv` and `all_contig.fasta`, provide the desired file prefix with `--file_prefix`.\n",
    "\n",
    "## Optional arguments\n",
    "\n",
    "By default, this workflow will analyse all provided IG samples jointly with TIgGER to maximise inference power, and in the event of multiple input folders will prepend the sample IDs to the cell barcodes to avoid erroneously merging barcodes overlapping between samples at this stage. TIgGER should be ran on a per-individual level. If running the workflow on multiple individuals' worth of data at once, or wanting to flag the cell barcodes in a non-default manner, information can be provided to the script in the form of a CSV file passed through the `--meta` argument:\n",
    "\n",
    "- The first row of the CSV needs to be a header identifying the information in the columns, and the first column needs to contain sample IDs.\n",
    "- Barcode flagging can be controlled by an optional `prefix`/`suffix` column. The pipeline will then add the specified prefixes/suffixes to the barcodes of the samples. This may be desirable, as corresponding gene expression samples are likely to have different IDs, and providing the matched ID will pre-format the BCR output to match the GEX nomenclature.\n",
    "- Individual information for TIgGER can be specified in an optional `individual` column. If specified, TIgGER will be ran for each unique value present in the column, pooling the corresponding samples.\n",
    "\n",
    "It's possible to just pass a prefix/suffix or individual information. An excerpt of a sample CSV file that could be used on input:\n",
    "\n",
    "    sample,suffix,individual\n",
    "    5841STDY7998693,5841STDY7991475,A37\n",
    "    WSSS_A_LNG9030827,WSSS_A_LNG8986832,A51\n",
    "    WSSS8090101,WSSS8015042,A40\n",
    "    [...]\n",
    "\n",
    "The delimiter between the barcode and the prefix/suffix can be controlled with the `--sep` argument. By default, the workflow will strip out the trailing `\"-1\"` from the Cellranger ouput barcode names; pass `--keep_trailing_hyphen_number` if you don't want to do that. Pass `--clean_output` if you want to remove intermediate files and just keep the primary output. The intermediate files may be useful for more detailed inspection.\n",
    "\n",
    "## Output\n",
    "\n",
    "The main file of interest will be `dandelion/data/filtered_contig_igblast_db-pass_genotyped.tsv`, stored in each sample folder. This is an AIRR formatted export of the corrected contigs, which can be used for downstream analysis by both Dandelion itself, and other packages like [Scirpy](https://icbi-lab.github.io/scirpy/generated/scirpy.io.read_airr.html) and changeo.\n",
    "\n",
    "The plots showing the impact of TIgGER are in `<tigger>/<tigger>_reassign_alleles.pdf`, for each TIgGER folder (one per unique individual if using `--meta`, `tigger` otherwise). The impact of C gene reannotation is shown in `dandelion/data/assign_isotype.pdf` for each sample.\n",
    "\n",
    "If you're interested in more detail about the pre-processing this offers, or wish to use the workflow in a more advanced manner (e.g. by using your own databases), proceed to the pre-processing section of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
