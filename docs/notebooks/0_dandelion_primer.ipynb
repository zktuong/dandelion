{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dandelion class\n",
    "\n",
    "Much of the functions and utility of the `dandelion` package revolves around the `Dandelion` class object. The class will act as an intermediary object for storage and flexible interaction with other tools. This section will run through a quick primer to the `Dandelion` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import modules</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.expanduser(\"~/Downloads/dandelion_tutorial/\"))\n",
    "import dandelion as ddl\n",
    "\n",
    "ddl.logging.print_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj = ddl.read_h5ddl(\"dandelion_results.h5ddl\")\n",
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the `.data` slot holds the AIRR contig table while the `.metadata` holds a collapsed version that is compatible with combining with `AnnData`'s `.obs` slot. You can retrieve these slots like a typical class object; for example, if I want the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slicing\n",
    "\n",
    "You can slice the `Dandelion` object via the `.data` or `.metadata` via their indices, with the behavior similar to how it is in pandas `DataFrame` and `AnnData`.\n",
    "\n",
    "<b>slicing</b> `.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the largest clone\n",
    "largest_clone = vdj.data[\"clone_id\"].value_counts().idxmax()\n",
    "\n",
    "vdj[vdj.data[\"clone_id\"] == largest_clone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj[\n",
    "    vdj.data_names.isin(\n",
    "        [\n",
    "            \"sc5p_v2_hs_PBMC_10k_AAACCTGTCATATCGG_contig_1\",\n",
    "            \"sc5p_v2_hs_PBMC_10k_AAACCTGTCCGTTGTC_contig_2\",\n",
    "            \"sc5p_v2_hs_PBMC_10k_AAACCTGTCCGTTGTC_contig_1\",\n",
    "            \"sc5p_v2_hs_PBMC_10k_AAACCTGTCGAGAACG_contig_1\",\n",
    "            \"sc5p_v2_hs_PBMC_10k_AAACCTGTCGAGAACG_contig_2\",\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**slicing** `.metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj[vdj.metadata[\"productive_VDJ\"].isin([\"T\", \"T|T\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj[vdj.metadata_names == \"vdj_v1_hs_pbmc3_TTTCCTCAGCGCTTAT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy\n",
    "\n",
    "You can deep copy the `Dandelion` object to another variable which will inherit all slots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj2 = vdj.copy()\n",
    "vdj2.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving entries with `update_metadata`\n",
    "\n",
    "The `.metadata` slot in Dandelion class automatically initializes whenever the `.data` slot is filled. However, it only returns a standard number of columns that are pre-specified. To retrieve other columns from the `.data` slot, we can update the metadata with `ddl.update_metadata` and specify the options `retrieve` and `retrieve_mode`. \n",
    "\n",
    "The following modes determine how the retrieval is completed:\n",
    "\n",
    "`split and unique only` - splits the retrieval into VDJ and VJ chains. A `|` will separate _**unique**_ element.\n",
    "\n",
    "`split and merge` - splits the retrieval into VDJ and VJ chains. A `|` will separate _**every**_ element.\n",
    "\n",
    "`merge and unique only` - smiliar to above but merged into a single column.\n",
    "\n",
    "`split` - split retrieval into _**individual**_ columns for each contig.\n",
    "\n",
    "`merge` - merge retrieval into a _**single**_ column where a `|` will separate _**every**_ element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical columns, there's additional options:\n",
    "\n",
    "`split and sum` - splits the retrieval into VDJ and VJ chains and sum separately.\n",
    "\n",
    "`split and average` - smiliar to above but average instead of sum.\n",
    "\n",
    "`sum` - sum the retrievals into a single column.\n",
    "\n",
    "`average` - averages the retrievals into a single column.\n",
    "\n",
    "If `retrieve_mode` is not specified, it will default to `split and merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Example: retrieving fwr1 sequences***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.update_metadata(retrieve=\"fwr1\")\n",
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the additional `fwr1` VDJ and VJ columns in the metadata slot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `dandelion` will not try to merge numerical columns as it can create mixed dtype columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a new sub-function that will try and retrieve frequently used columns such as `np1_length`, `np2_length`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.update_plus()\n",
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming barcodes\n",
    "\n",
    "You can now use a simple function to rename the barcodes (both sequence and cell ids at the same time). This is useful for when you want to rename the barcodes to a more meaningful name. This only works on the indices that were initially used to create the `Dandelion` object. So if you have run the function once already, it doesn't continuously add the prefix/suffix to the new indices. It just updates based on the original indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "print(vdj.data[[\"sequence_id\", \"cell_id\"]]), print(vdj.metadata_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a 'test-' as a prefix. There's also the suffix option\n",
    "vdj.add_sequence_prefix(\"test\", sep=\"-\")\n",
    "print(vdj.data[[\"sequence_id\", \"cell_id\"]]), print(vdj.metadata_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same functionality as above\n",
    "vdj.add_cell_prefix(\"test2\", sep=\"_\")\n",
    "print(vdj.data[[\"sequence_id\", \"cell_id\"]]), print(vdj.metadata_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also reset the ids\n",
    "vdj.reset_ids()\n",
    "print(vdj.data[[\"sequence_id\", \"cell_id\"]]), print(vdj.metadata_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the V/DJ/C call annotations\n",
    "\n",
    "Sometimes the V/DJ/C call annotations can be quite verbose. You can simplify them with the `.simplify()` function. This function will remove the `,` and only keep the first element of the call, as well as stripping alleles. This is useful for when you want to simplify the V/DJ/C calls for plotting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before\n",
    "(\n",
    "    vdj.data[[\"v_call_genotyped\", \"j_call\"]],\n",
    "    vdj.metadata[[\"v_call_genotyped_VDJ\", \"j_call_VDJ\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after\n",
    "vdj.simplify()\n",
    "# before\n",
    "(\n",
    "    vdj.data[[\"v_call_genotyped\", \"j_call\"]],\n",
    "    vdj.metadata[[\"v_call_genotyped_VDJ\", \"j_call_VDJ\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenating multiple objects\n",
    "\n",
    "This is a simple function to concatenate (append) two or more `Dandelion` class, or `pandas` dataframes. Note that this operates on the `.data` slot and not the `.metadata` slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, the original dandelion class has 2071 unique cell barcodes and 4882 contigs\n",
    "vdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it has 14646 (4882*3) contigs instead, and the metadata should also be properly populated\n",
    "vdj_concat = ddl.concat([vdj, vdj, vdj])\n",
    "vdj_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj_concat.data[[\"sequence_id\", \"cell_id\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ddl.concat` also lets you add in your custom prefixes/suffixes to append to the sequence ids. If not provided, it will add `-0`, `-1` etc. as a suffix if it detects that the sequence ids are not unique as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read/write\n",
    "\n",
    "`Dandelion` class can be saved using `.write_h5ddl` and `.write_pkl` functions with accompanying compression methods e.g. `gzip`. `write_h5ddl` primarily uses `h5py` library and `write_pkl` just uses pickle. `read_h5ddl` and `read_pkl` functions will read the respective file formats accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time vdj.write_h5ddl('dandelion_results.h5ddl', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see any warnings above, it's due to mix dtypes somewhere in the object. So do some checking if you think it will interfere with downstream usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time vdj_1 = ddl.read_h5ddl('dandelion_results.h5ddl')\n",
    "vdj_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The read/write times using `pickle` can be situationally faster/slower and file sizes can also be situationally smaller/larger (depending on which compression is used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time vdj.write_pkl('dandelion_results.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time vdj_2 = ddl.read_pkl('dandelion_results.pkl.gz')\n",
    "vdj_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also other types of writing functions such as `.write_airr` and `.write_10x`, which will write the object to a `.tsv` or `.csv` file that is compatible with `airr` and `10x` formats respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vdj2.write_airr(\"test.airr.tsv\")\n",
    "df = pd.read_csv(\"test.airr.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj2.write_10x(\n",
    "    folder=\"10x_test\",\n",
    "    filename_prefix=\"all\",\n",
    ")  # this writes both the conting_annotations.csv and contig.fasta\n",
    "df = pd.read_csv(\"10x_test/all_contig_annotations.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandelion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
