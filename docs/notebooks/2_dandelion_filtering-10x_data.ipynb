{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "We now move on to filtering out BCR contigs (and corresponding cells if necessary) from the BCR data and transcriptome object loaded in *scanpy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import <i>dandelion</i> module</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dandelion as ddl\n",
    "\n",
    "# change directory to somewhere more workable\n",
    "os.chdir(os.path.expanduser(\"~/Downloads/dandelion_tutorial/\"))\n",
    "ddl.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import modules for use with scanpy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import the transcriptome data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"sc5p_v2_hs_PBMC_1k\",\n",
    "    \"sc5p_v2_hs_PBMC_10k\",\n",
    "    \"vdj_v1_hs_pbmc3\",\n",
    "    \"vdj_nextgem_hs_pbmc3\",\n",
    "]\n",
    "adata_list = []\n",
    "for sample in samples:\n",
    "    adata = sc.read_10x_h5(\n",
    "        sample + \"/filtered_feature_bc_matrix.h5\", gex_only=True\n",
    "    )\n",
    "    adata.obs[\"sampleid\"] = sample\n",
    "    # rename cells to sample id + barcode\n",
    "    adata.obs_names = [str(sample) + \"_\" + str(j) for j in adata.obs_names]\n",
    "    adata.var_names_make_unique()\n",
    "    adata_list.append(adata)\n",
    "adata = adata_list[0].concatenate(adata_list[1:])\n",
    "# rename the obs_names again, this time cleaving the trailing -#\n",
    "adata.obs_names = [str(j).split(\"-\")[0] for j in adata.obs_names]\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using a wrapper called `pp.recipe_scanpy_qc` to run through a generic [scanpy](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) workflow. You can skip this if you already have a pre-processed `AnnData` object for the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pp.recipe_scanpy_qc(adata, mito_cutoff=None)  # use a gmm model to decide\n",
    "# we can continue with those that survive qc\n",
    "adata = adata[adata.obs[\"filter_rna\"] == \"False\"].copy()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter cells that are potental doublets and poor quality in both the V(D)J data and transcriptome data\n",
    "\n",
    "### `ddl.pp.check_contigs`\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Deprecation warning\n",
    "\n",
    "Pre v0.5.0, there are two separate functions to perform contig QC with either `ddl.pp.filter_contigs` or `ddl.pp.check_contigs` to deal with poor quality contigs, either explicitly removing them or just flagging them. From v0.5.0 onwards however, `ddl.pp.filter_contigs` is deprecated and will be removed in v0.5.0, and `ddl.pp.check_contigs` will be the only QC option going forward. `ddl.pp.check_contigs` is easier to maintain and simply marks the problematic contigs as `ambiguous` and withhold them from downstream analysis. The new version of `ddl.pp.check_contigs` will also have the `filter_extra` and `filter_ambiguous` options to remove/keep the `extra` (marked due to passing the internal QC filters but not explicitly ambiguous) and `ambiguous` contigs, fulfilling the same utility as `ddl.pp.filter_contigs`.\n",
    "</div>\n",
    "\n",
    "We use the function `pp.check_contigs` to mark and filter out cells and contigs from both the V(D)J data and transcriptome data in `AnnData`. The operation will remove bad quality cells based on transcriptome information as well as remove V(D)J doublets (multiplet heavy/long chains, and/or light/short chains) from the V(D)J data. In some situations, a single cell can have multiple heavy/long and light/short chain contigs although they have an identical V(D)J+C alignment; in situations like this, the contigs with lesser UMIs will be dropped and the UMIs transferred to `umi_count` column. The same procedure is applied to both chains before further checks of the annotation quality, UMI and consensus count distributions.\n",
    "\n",
    "Cells in the gene expression object without V(D)J information will not be affected which means that the `AnnData` object can hold non-B/T cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we read in the 4 bcr files\n",
    "bcr_files = []\n",
    "for sample in samples:\n",
    "    file_location = sample + \"/dandelion/filtered_contig_dandelion.tsv\"\n",
    "    bcr_files.append(pd.read_csv(file_location, sep=\"\\t\"))\n",
    "bcr = pd.concat(bcr_files, ignore_index=True)\n",
    "bcr.reset_index(inplace=True, drop=True)\n",
    "bcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Library type\n",
    "    \n",
    "It is recommended to specify the <b><b>library_type</b></b> argument as it will remove all contigs that do not belong to the related loci. The rationale is that the choice of the library type should mean that the primers used would most likely amplify those related sequences and if there's any unexpected loci, they likely represent artifacts and shouldn't be analysed. The optional argument accepts: `ig`, `tr-ab`, `tr-gd` or `None` where `None` means all contigs will be kept.\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main output of this function are two an additional columns in `vdj.data`, `extra` and `ambiguous`, which flags `T` or `F` for contigs that were marked accordingly. The rules for marking contigs are as follows:\n",
    "\n",
    "`extra` is marked as `T` if the contig passes the internal QC filters based on `umi_count` (or `consensus_count` if there are ties in the `umi_count`) in a cell. If you are only interested in just the top contig pair, you can set `filter_extra=True` to remove the extra contigs.\n",
    "\n",
    "For VDJ chains, the current rule set is to keep the **top 1** `productive` contig with the highest counts and mark the rest as `extra` (or `ambiguous` if appropriate). Toggle `ntop_vdj` to keep the top `n` (default 1) contigs.\n",
    "\n",
    "For VJ chains, the current rule set is to keep the **top 2** `productive` contigs with the highest counts and mark the rest as `extra` (or `ambiguous` if appropriate). Toggle `ntop_vj` to keep the top `n` (default 2) contigs.\n",
    "\n",
    "`ambiguous` is marked as `T` if the contig is of poor quality annotation and would be removed from downstream analysis. Cells with multiple contigs with very low `umi_counts` and/or `consensus_counts` are also marked as `ambiguous` as it is not possible to distinguish which is the most representative contig.\n",
    "\n",
    "Please note that the default for `filter_extra` is `True`. If you want to keep the `extra` contigs for whatever reasons e.g. interested in T/B-cell development datasets, you need to set `filter_extra=False`. We are setting this as `False` in this example because later on we want to visualise these extra contigs.\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj, adata = ddl.pp.check_contigs(\n",
    "    bcr, adata, library_type=\"ig\", filter_extra=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check the Dandelion object</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check the AnnData object as well</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the relevant columns for looking at the QC status of the cells and contigs in the `.obs` slot in the `AnnData` object (and also `.metadata` slot in the `Dandelion` object):\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Relevant columns in obs\n",
    "\n",
    "- `has_contig`\n",
    "- whether cells have V(D)J chains.<br><br>\n",
    "    \n",
    "- `locus_status`\n",
    "- detailed information on chain status pairings (below).<br><br>\n",
    "    \n",
    "- `chain_status`\n",
    "- summarised information of the chain locus status pairings (similar to `chain_pairing` in `scirpy`).<br><br>\n",
    "    \n",
    "- `rearrangement_status_VDJ` and  `rearrangement_status_VJ`\n",
    "- whether or not V(D)J gene usage are standard (i.e. all from the same locus).\n",
    "\n",
    "</div>\n",
    "\n",
    "So in a standard situation, I would remove cells flagged with `Orphan VJ`, `Orphan VJ-exception`, `ambiguous` in `.metadata.chain_status`, and also any cell marked as `chimeric` in the `.metadata.rearrangement_status_VDJ` and `.metadata.rearrangement_status_VJ` from downstream cell-level calculations/analysis. \n",
    "\n",
    "Having said that, you will find that most of `Dandelion`'s functions will work without the need to requirement to perform additional filtering and filtering can be performed on the final `AnnData` object (described in the visualisation section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let's take a look at these new columns</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(adata.obs[\"chain_status\"], adata.obs[\"locus_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if there are multiple library types, i.e. `ddl.pp.filter_contigs` or `ddl.pp.check_contigs` was run with `library_type = None`, or if several tcr/bcr `Dandelion` objects are concatenated, there will be additional columns where the `v/d/j/c calls` and `productive` will be split into additional columns to reflect those that belong to a B cell, alpha-beta T cell, or gamma-delta T cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this `contig_checked` object going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now actually filter the AnnData object and run through a standard workflow starting by filtering genes and normalizing the data\n",
    "\n",
    "Because the 'filtered' `AnnData` object was returned as a filtered but otherwise unprocessed object, we still need to normalize and run through the usual process here. The following is just a standard scanpy workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter genes\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "# Normalize the counts\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "# Logarithmize the data\n",
    "sc.pp.log1p(adata)\n",
    "# Stash the normalised counts\n",
    "adata.raw = adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Identify highly-variable genes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Filter the genes to only those marked as highly-variable</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:, adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. Scale the data to unit variance.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.regress_out(adata, [\"total_counts\", \"pct_counts_mt\"])\n",
    "sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run PCA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pl.pca_variance_ratio(adata, log=True, n_pcs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Computing the neighborhood graph, umap and clusters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the neighborhood graph\n",
    "sc.pp.neighbors(adata)\n",
    "# Embedding the neighborhood graph\n",
    "sc.tl.umap(adata)\n",
    "# Clustering the neighborhood graph\n",
    "sc.tl.leiden(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualizing the clusters and whether or not there's a corresponding V(D)J receptor</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"leiden\", \"chain_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualizing some B cell genes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"IGHM\", \"JCHAIN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Save AnnData</b>\n",
    "\n",
    "We can save this `AnnData` object for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"adata.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Save dandelion</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the vdj object, we have two options - either save the `.data` and `.metadata` slots with pandas' functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.data.to_csv(\"filtered_vdj_table.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or save the whole Dandelion class object with either `.write_h5ddl/.write`, which saves the class to a HDF5 format, or using a pickle-based `.write_pkl` function.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "From v0.4.0, the `.write_h5ddl/.write` function has been refactored to use `h5py`. Support for files saved prior to v0.4.0 (which used `pandas` to save in HDF5 format) will be maintained at least until the next major version and `ddl.read_h5ddl` will be able to read both old and new versions. The old version can be saved with `.write_h5ddl(..., version=3)` but this is not covered by tests because of issues with installing the dependencies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.write_h5ddl(\"dandelion_results.h5ddl\")  # can add compression=\"gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.write_pkl(\n",
    "    \"dandelion_results.pkl.pbz2\"\n",
    ")  # this will automatically use bzip2 for compression, switch the extension to .gz for gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running `ddl.pp.check_contigs` without `AnnData`\n",
    "\n",
    "Finally, `ddl.pp.check_contigs` can also be run without an `AnnData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj3 = ddl.pp.check_contigs(bcr)\n",
    "vdj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandelion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
