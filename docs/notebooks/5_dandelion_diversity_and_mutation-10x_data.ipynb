{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating diversity and mutation\n",
    "\n",
    "## Calculating mutational load\n",
    "To calculate mutational load, the functions from `immcantation` suite's `shazam` [[Gupta2015]](https://academic.oup.com/bioinformatics/article/31/20/3356/195677) can be accessed via `rpy2` to work with the `dandelion` class object.\n",
    "\n",
    "This can be run immediately after `pp.reassign_alleles` during the reannotation pre-processing stage because the required germline columns should be present in the genotyped `.tsv` file. I would recommend to run this after TIgGER [[Gadala-Maria2015]](https://www.pnas.org/content/112/8/E862), after the v_calls were corrected. Otherwise, if the reannotation was skipped, you can run it now as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import modules</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dandelion as ddl\n",
    "\n",
    "ddl.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to somewhere more workable\n",
    "os.chdir(os.path.expanduser(\"~/Downloads/dandelion_tutorial/\"))\n",
    "# I'm importing scanpy here to make use of its logging module.\n",
    "import scanpy as sc\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read in the previously saved files</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"adata.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj = ddl.read_h5ddl(\"dandelion_results.h5ddl\")\n",
    "vdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's recreate the vdj object with only the first two samples\n",
    "subset_data = vdj.data[\n",
    "    vdj.data[\"sample_id\"].isin([\"sc5p_v2_hs_PBMC_1k\", \"sc5p_v2_hs_PBMC_10k\"])\n",
    "]\n",
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Dandelion class with this subset\n",
    "vdj2 = ddl.Dandelion(subset_data)\n",
    "vdj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `store_germline_reference`\n",
    "\n",
    "We can store the corrected germline fasta files (after running TIgGER) in the `Dandelion` class as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the germline using the corrected files after tigger\n",
    "vdj2.store_germline_reference(\n",
    "    corrected=\"tutorial_scgp1/tutorial_scgp1_heavy_igblast_db-pass_genotype.fasta\",\n",
    "    germline=None,\n",
    "    org=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pp.create_germlines`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run `pp.create_germline` to (re)create the `germline_alignment_d_mask` column in the data. This works by calling `CreateGermlines.py` with only `-d` and `-r` options. Add further arguments with `additional_args` like below for your needs. See https://changeo.readthedocs.io/en/stable/examples/germlines.html for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pp.create_germlines(vdj2, additional_args=[\"--vf\", \"v_call_genotyped\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the `germline_alignment_d_mask` column is populated or subsequent steps will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj2.data[[\"v_call_genotyped\", \"germline_alignment_d_mask\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default behaviour is to mask the D region with Ns with option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pp.quantify_mutations`\n",
    "\n",
    "The options for `pp.quantify_mutations` are the same as the basic mutational load analysis [vignette](https://shazam.readthedocs.io/en/version-0.1.8---mutation-profiling-enhancements/vignettes/Mutation-Vignette/) [[Gupta2015]](https://academic.oup.com/bioinformatics/article/31/20/3356/195677). The default behavior is to sum all mutations scores (heavy and light chains, silent and replacement mutations) for the same cell.\n",
    "\n",
    "Again, this function can be run immediately after `pp.reassign_alleles` on the genotyped `.tsv` files (without loading into `pandas` or `Dandelion`). Here I'm illustrating a few other options that may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switching back to using the full vdj object\n",
    "ddl.pp.quantify_mutations(vdj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pp.quantify_mutations(vdj, combine=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying `split_locus = True` will split up the results for the different chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pp.quantify_mutations(vdj, split_locus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the `AnnData` object, simply rerun `tl.transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.transfer(adata, vdj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanpy.plotting.palettes import default_28, default_102\n",
    "\n",
    "sc.set_figure_params(figsize=[4, 4])\n",
    "ddl.pl.clone_network(\n",
    "    adata,\n",
    "    color=[\n",
    "        \"clone_id\",\n",
    "        \"mu_count\",\n",
    "        \"mu_count_seq_r\",\n",
    "        \"mu_count_seq_s\",\n",
    "        \"mu_count_IGH\",\n",
    "        \"mu_count_IGL\",\n",
    "    ],\n",
    "    ncols=2,\n",
    "    legend_loc=\"none\",\n",
    "    legend_fontoutline=3,\n",
    "    edges_width=1,\n",
    "    palette=default_28 + default_102,\n",
    "    color_map=\"viridis\",\n",
    "    size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating diversity\n",
    "\n",
    "*Disclaimer: the functions here are experimental. Please look to other sources/methods for doing this properly. Also, would appreciate any help to help me finalise this!* \n",
    "\n",
    "`tl.clone_rarefaction` and `pl.clone_rarefaction`\n",
    "\n",
    "We can use `pl.clone_rarefaction` to generate rarefaction curves for the clones. `tl.clone_rarefaction` will populate the `.uns` slot with the results. `groupby` option must be specified. In this case, I decided to group by sample. The function will only work on an `AnnData` object and not a `Dandelion` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pl.clone_rarefaction(adata, color=\"sampleid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ddl.tl.clone_diversity`\n",
    "\n",
    "`tl.clone_diversity` allows for calculation of diversity measures such as <b>Chao1</b>, <b>Shannon Entropy</b> and <b>Gini indices</b>. \n",
    "\n",
    "While the function can work on both `AnnData` and `Dandelion` objects, the methods for gini index calculation will only work on a `Dandelion` object as it requires access to the network. \n",
    "\n",
    "For Gini indices, we provide several types of measures, inspired by bulk BCRseq analysis methods from [[Bashford-Rogers2013]](https://genome.cshlp.org/content/23/11/1874):\n",
    "\n",
    "The following two indices are returned with `metric=\"clone_network\"`.\n",
    "   \n",
    "   <b>I. network cluster/clone size Gini index</b> \n",
    "    \n",
    "   In a contracted BCR network (where identical BCRs are collapsed into the same node/vertex), disparity in the distribution should be correlated to the amount of mutation events i.e. larger networks should indicate more mutation events and smaller networks should indicate lesser mutation events.\n",
    "\n",
    "   <b>II. network vertex/node size Gini index</b>\n",
    "    \n",
    "   In the same contracted network, we can count the number of merged/contracted nodes; nodes with higher count numbers indicate more clonal expansion. Thus, disparity in the distribution of count numbers (referred to as vertex size) should be correlated to the overall clonality i.e. clones with larger vertex sizes are more monoclonal and clones with smaller vertex sizes are more polyclonal.\n",
    "    \n",
    "Therefore, a Gini index of 1 on either measures repesents perfect inequality (i.e. monoclonal and highly mutated) and a value of 0 represents perfect equality (i.e. polyclonal and unmutated).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Note\n",
    "\n",
    "However, there are a few limitations/challenges that comes with single-cell data: \n",
    "\n",
    "- <b>A.</b> In the process of contracting the network, we discard the single-cell level information. <br><br>\n",
    "\n",
    "- <b>B.</b> Contraction of network is very slow, particularly when there is a lot of clonally-related cells. <br><br>\n",
    "\n",
    "- <b>C.</b> For the full implementation and interpretation of both measures, although more evident with cluster/clone size, it requires the BCR repertoire to be reasonably/deeply sampled and we know that this is currently limited by the low recovery from single cell data with current technologies.\n",
    "\n",
    "</div>\n",
    "\n",
    "Therefore, we implement a few work around options, and 'experimental' options below, to try and circumvent these issues.\n",
    "\n",
    "Firstly, as a work around for (C), the cluster size gini index can be calculated before or after network contraction. If performing before network contraction (default), it will be calculated based on the size of subgraphs of connected components in the main graph. This will retain the single-cell information and should appropriately show the distribution of the data. If performing after network contraction, the calculation is performed after network contraction, achieving the same effect as the method for bulk BCR-seq as described above. This option can be toggled by `use_contracted` and only applies to network cluster size gini index calculation.\n",
    "\n",
    "   <b>III. clone centrality Gini index</b> - `metric=\"clone_centrality\"`\n",
    "   \n",
    "   Node/vertex closeness centrality indicates how tightly packed clones are (more clonally related) and thus the distribution of the number of cells connected in each clone informs on whether clones in general are more monoclonal or polyclonal.\n",
    "\n",
    "   <b>IV. clone degree Gini index</b> - `metric=\"clone_degree\"`\n",
    "   \n",
    "   Node/vertex degree indicates how many cells are connected to an individual cell, another indication of how clonally related cells are. However, this would also highlight cells that are in the middle of large networks but are not necessarily within clonally expanded regions (e.g. intermediate connecting cells within the minimum spanning tree).\n",
    " \n",
    "   <b>V. clone size Gini index</b> - `metric=\"clone_size\"`\n",
    "   \n",
    "   This is not to be confused with the network cluster size gini index calculation above as this doesn't rely on the network, although the values should be similar. This is just a simple implementation based on the data frame for the relevant `clone_id` column. By default, this metric is also returned when running `metric=clone_centrality` or `metric=clone_degree`.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Note\n",
    "\n",
    "For (I) and (II), we can specify `expanded_only` option to compute the statistic for all clones or expanded only clones. Unlike options (I) and (II), the current calculation for (III) and (IV) is largely influenced by the amount of expanded clones i.e. clones with at least 2 cells, and not affected by the number of singleton clones because singleton clones will have a value of 0 regardless.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diversity functions also have the option to perform downsampling to a fixed number of cells, or to the smallest sample size specified via `groupby` (default) so that sample sizes are even when comparing between groups.\n",
    "\n",
    "if `return_table=True`, a data frame is returned; otherwise, the value gets added to the `AnnData.obs` or `Dandelion.metadata` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 1  # it gets very noisy\n",
    "ddl.tl.clone_diversity(\n",
    "    vdj, groupby=\"sample_id\", method=\"gini\", metric=\"clone_network\"\n",
    ")\n",
    "ddl.tl.clone_diversity(\n",
    "    vdj, groupby=\"sample_id\", method=\"gini\", metric=\"clone_centrality\"\n",
    ")\n",
    "ddl.tl.transfer(adata, vdj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pl.clone_network(\n",
    "    adata,\n",
    "    color=[\n",
    "        \"clone_network_cluster_size_gini\",\n",
    "        \"clone_network_vertex_size_gini\",\n",
    "        \"clone_size_gini\",\n",
    "        \"clone_centrality_gini\",\n",
    "    ],\n",
    "    ncols=2,\n",
    "    size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these particular samples, because there is not many expanded clones in general, the gini indices are quite low when calculated within each sample. We can re-run it by specifying `expanded_only = True` to only factor in expanded clones. We also specify the `key_added` option to create a new column instead of writing over the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.clone_diversity(\n",
    "    vdj,\n",
    "    groupby=\"sample_id\",\n",
    "    method=\"gini\",\n",
    "    metric=\"clone_network\",\n",
    "    expanded_only=True,\n",
    "    key_added=[\n",
    "        \"clone_network_cluster_size_gini_expanded\",\n",
    "        \"clone_network_vertex_size_gini_expanded\",\n",
    "    ],\n",
    ")\n",
    "ddl.tl.transfer(adata, vdj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pl.clone_network(\n",
    "    adata,\n",
    "    color=[\n",
    "        \"clone_network_cluster_size_gini_expanded\",\n",
    "        \"clone_network_vertex_size_gini_expanded\",\n",
    "    ],\n",
    "    ncols=2,\n",
    "    size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also choose not to update the metadata to return a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini = ddl.tl.clone_diversity(\n",
    "    vdj, groupby=\"sample_id\", method=\"gini\", return_table=True\n",
    ")\n",
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini2 = ddl.tl.clone_diversity(\n",
    "    vdj,\n",
    "    groupby=\"sample_id\",\n",
    "    method=\"gini\",\n",
    "    return_table=True,\n",
    "    expanded_only=True,\n",
    "    key_added=[\n",
    "        \"clone_network_cluster_size_gini_expanded\",\n",
    "        \"clone_network_vertex_size_gini_expanded\",\n",
    "    ],\n",
    ")\n",
    "gini2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p = sns.scatterplot(\n",
    "    x=\"clone_network_cluster_size_gini\",\n",
    "    y=\"clone_network_vertex_size_gini\",\n",
    "    data=gini,\n",
    "    hue=gini.index,\n",
    "    palette=dict(\n",
    "        zip(adata.obs[\"sampleid\"].cat.categories, adata.uns[\"sampleid_colors\"])\n",
    "    ),\n",
    ")\n",
    "p.set(ylim=(-0.1, 1), xlim=(-0.1, 1))\n",
    "plt.legend(bbox_to_anchor=(1, 0.5), loc=\"center left\", frameon=False)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = sns.scatterplot(\n",
    "    x=\"clone_network_cluster_size_gini_expanded\",\n",
    "    y=\"clone_network_vertex_size_gini_expanded\",\n",
    "    data=gini2,\n",
    "    hue=gini2.index,\n",
    "    palette=dict(\n",
    "        zip(adata.obs[\"sampleid\"].cat.categories, adata.uns[\"sampleid_colors\"])\n",
    "    ),\n",
    ")\n",
    "p2.set(ylim=(-0.1, 1), xlim=(-0.1, 1))\n",
    "plt.legend(bbox_to_anchor=(1, 0.5), loc=\"center left\", frameon=False)\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise what the results for the clone centrality gini indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini = ddl.tl.clone_diversity(\n",
    "    vdj,\n",
    "    groupby=\"sample_id\",\n",
    "    method=\"gini\",\n",
    "    metric=\"clone_centrality\",\n",
    "    return_table=True,\n",
    ")\n",
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not a great example because there's only 1 big clone in 1 sample.\n",
    "p = sns.scatterplot(\n",
    "    x=\"clone_size_gini\",\n",
    "    y=\"clone_centrality_gini\",\n",
    "    data=gini,\n",
    "    hue=gini.index,\n",
    "    palette=dict(\n",
    "        zip(adata.obs[\"sampleid\"].cat.categories, adata.uns[\"sampleid_colors\"])\n",
    "    ),\n",
    ")\n",
    "p.set(ylim=(-0.1, 1), xlim=(-0.1, 1))\n",
    "plt.legend(bbox_to_anchor=(1, 0.5), loc=\"center left\", frameon=False)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chao1 is an estimator based on abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.clone_diversity(\n",
    "    vdj, groupby=\"sample_id\", method=\"chao1\", return_table=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Shannon Entropy, we can calculate a normalized (inspired by [scirpy's function](https://icbi-lab.github.io/scirpy/generated/scirpy.tl.alpha_diversity.html?highlight=diversity#scirpy.tl.alpha_diversity)) and non-normalized value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.clone_diversity(\n",
    "    vdj, groupby=\"sample_id\", method=\"shannon\", return_table=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.clone_diversity(\n",
    "    vdj,\n",
    "    groupby=\"sample_id\",\n",
    "    method=\"shannon\",\n",
    "    update_obs_meta=False,\n",
    "    normalize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That sums it up for now! Let me know if you have any ideas at [z.tuong@uq.edu.au] and I can try and see if i can implement it or we can work something out to collaborate on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj2.write_h5ddl(\"test.h5ddl\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dandelion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
