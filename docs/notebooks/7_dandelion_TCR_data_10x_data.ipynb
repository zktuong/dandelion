{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing TCR data\n",
    "\n",
    "With `dandelion>=1.3` onwards, there will be the ability to start analyzing 10x single-cell TCR data with the existing setup for both alpha-beta and gamma-delta TCR data formats. Currently, the alpha-beta and gamma-delta data sets have to be analyzed separately.\n",
    "\n",
    "We will download the various input formats of TCR files from 10x's [resource page](https://www.10xgenomics.com/resources/datasets) as part of this tutorial:\n",
    "\n",
    "```bash\n",
    "# bash\n",
    "mkdir -p dandelion_tutorial/sc5p_v2_hs_PBMC_10k;\n",
    "mkdir -p dandelion_tutorial/sc5p_v1p1_hs_melanoma_10k;\n",
    "\n",
    "cd dandelion_tutorial/sc5p_v2_hs_PBMC_10k;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_filtered_feature_bc_matrix.h5;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_t_airr_rearrangement.tsv;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_t_filtered_contig_annotations.csv;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_t_filtered_contig.fasta;\n",
    "\n",
    "cd ../sc5p_v1p1_hs_melanoma_10k;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v1p1_hs_melanoma_10k/sc5p_v1p1_hs_melanoma_10k_filtered_feature_bc_matrix.h5;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v1p1_hs_melanoma_10k/sc5p_v1p1_hs_melanoma_10k_t_airr_rearrangement.tsv;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v1p1_hs_melanoma_10k/sc5p_v1p1_hs_melanoma_10k_t_filtered_contig_annotations.csv;\n",
    "wget https://cf.10xgenomics.com/samples/cell-vdj/4.0.0/sc5p_v1p1_hs_melanoma_10k/sc5p_v1p1_hs_melanoma_10k_t_filtered_contig.fasta;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import dandelion module</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dandelion as ddl\n",
    "\n",
    "# change directory to somewhere more workable\n",
    "os.chdir(os.path.expanduser(\"~/Downloads/dandelion_tutorial/\"))\n",
    "ddl.logging.print_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm showing two examples for reading in the data: with or without reannotation.\n",
    "\n",
    "<b>Read in AIRR format</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the airr_rearrangement.tsv file\n",
    "file1 = \"sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_t_airr_rearrangement.tsv\"\n",
    "file2 = \"sc5p_v1p1_hs_melanoma_10k/sc5p_v1p1_hs_melanoma_10k_t_airr_rearrangement.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj1 = ddl.read_10x_airr(file1)\n",
    "vdj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj2 = ddl.read_10x_airr(file2)\n",
    "vdj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into a singular object\n",
    "# let's add the sample_id to each cell barcode so that we don't end up overlapping later on\n",
    "sample_id = \"sc5p_v2_hs_PBMC_10k\"\n",
    "vdj1.data[\"sample_id\"] = sample_id\n",
    "vdj1.data[\"cell_id\"] = [sample_id + \"_\" + c for c in vdj1.data[\"cell_id\"]]\n",
    "vdj1.data[\"sequence_id\"] = [\n",
    "    sample_id + \"_\" + s for s in vdj1.data[\"sequence_id\"]\n",
    "]\n",
    "\n",
    "sample_id = \"sc5p_v1p1_hs_melanoma_10k\"\n",
    "vdj2.data[\"sample_id\"] = sample_id\n",
    "vdj2.data[\"cell_id\"] = [sample_id + \"_\" + c for c in vdj2.data[\"cell_id\"]]\n",
    "vdj2.data[\"sequence_id\"] = [\n",
    "    sample_id + \"_\" + s for s in vdj2.data[\"sequence_id\"]\n",
    "]\n",
    "\n",
    "# combine into a singular object\n",
    "vdj = ddl.concat([vdj1, vdj2])\n",
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read in with reannotation</b>\n",
    "\n",
    "We specify the `filename_prefix` option because they have different prefixes that precedes `_contig.fasta` and `_contig_annotations.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"sc5p_v2_hs_PBMC_10k\", \"sc5p_v1p1_hs_melanoma_10k\"]\n",
    "filename_prefixes = [\n",
    "    \"sc5p_v2_hs_PBMC_10k_t_filtered\",\n",
    "    \"sc5p_v1p1_hs_melanoma_10k_t_filtered\",\n",
    "]\n",
    "ddl.pp.format_fastas(samples, prefix=samples, filename_prefix=filename_prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to toggle `loci = 'tr'` for TCR data. I'm setting `reassign_dj = True` so as to try and force a reassignment of J genes (and D genes if it can) with stricter cut offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pp.reannotate_genes(\n",
    "    samples, loci=\"tr\", reassign_dj=True, filename_prefix=filename_prefixes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no need to run the the rest of the preprocessing steps.\n",
    "\n",
    "We'll read in the reannotated files like as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tcr_files = []\n",
    "for sample in samples:\n",
    "    file_location = (\n",
    "        sample + \"/dandelion/\" + sample + \"_t_filtered_contig_dandelion.tsv\"\n",
    "    )\n",
    "    tcr_files.append(pd.read_csv(file_location, sep=\"\\t\"))\n",
    "tcr = pd.concat(tcr_files, ignore_index=True)\n",
    "tcr.reset_index(inplace=True, drop=True)\n",
    "tcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reannotated file can be used with dandelion as per the BCR tutorial.\n",
    "\n",
    "For the rest of the tutorial, I'm going to show how to proceed with 10x's AIRR format file instead as there are some minor differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import modules for use with scanpy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import the transcriptome data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_files = {\n",
    "    \"sc5p_v2_hs_PBMC_10k\": \"sc5p_v2_hs_PBMC_10k/sc5p_v2_hs_PBMC_10k_filtered_feature_bc_matrix.h5\",\n",
    "    \"sc5p_v1p1_hs_melanoma_10k\": \"sc5p_v1p1_hs_melanoma_10k/sc5p_v1p1_hs_melanoma_10k_filtered_feature_bc_matrix.h5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_list = []\n",
    "for f in gex_files:\n",
    "    adata_tmp = sc.read_10x_h5(gex_files[f], gex_only=True)\n",
    "    adata_tmp.obs[\"sample_id\"] = f\n",
    "    adata_tmp.obs_names = [f + \"_\" + x for x in adata_tmp.obs_names]\n",
    "    adata_tmp.var_names_make_unique()\n",
    "    adata_list.append(adata_tmp)\n",
    "adata = ad.concat(adata_list)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run QC on the transcriptome data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.pp.recipe_scanpy_qc(adata)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Filtering TCR data.</b>\n",
    "\n",
    "Note that I'm using the `Dandelion` object as input rather than the pandas dataframe (yes both types of input will works. In fact, a file path to the .tsv will work too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function will return both objects.\n",
    "vdj, adata = ddl.pp.check_contigs(vdj, adata, library_type=\"tr-ab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check the output V(D)J table</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check the AnnData object as well</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The number of cells that actually has a matching BCR can be tabluated.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(adata.obs[\"has_contig\"], adata.obs[\"chain_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now actually filter the AnnData object and run through a standard workflow starting by filtering genes and normalizing the data</b>\n",
    "\n",
    "Because the 'filtered' `AnnData` object was returned as a filtered but otherwise unprocessed object, we still need to normalize and run through the usual process here. The following is just a standard scanpy workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter genes\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "# Normalize the counts\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "# Logarithmize the data\n",
    "sc.pp.log1p(adata)\n",
    "# Stash the normalised counts\n",
    "adata.raw = adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Identify highly-variable genes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Filter the genes to only those marked as highly-variable</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:, adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. Scale the data to unit variance.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.regress_out(adata, [\"total_counts\", \"pct_counts_mt\"])\n",
    "sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run PCA</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pl.pca_variance_ratio(adata, log=True, n_pcs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Computing the neighborhood graph, umap and clusters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the neighborhood graph\n",
    "sc.pp.neighbors(adata)\n",
    "# Embedding the neighborhood graph\n",
    "sc.tl.umap(adata)\n",
    "# Clustering the neighborhood graph\n",
    "sc.tl.leiden(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualizing the clusters and whether or not there's a corresponding contig.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"leiden\", \"chain_status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualizing some T cell genes.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"CD3E\", \"CD8B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Find clones.</b>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "Here we specify `identity = 1` so only cells with identical CDR3 nucleotide sequences (`key = 'junction'`) are grouped into clones/clonotypes.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.find_clones(vdj, identity=1, key=\"junction\")\n",
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Generate TCR network.</b>\n",
    "\n",
    "The 10x-provided AIRR file is missing columns like `sequence_alignment` and `sequence_alignment_aa` so we will use the next best thing, which is `sequence` or `sequence_aa`. Note that these columns are not-gapped.\n",
    "\n",
    "Specify `key = 'sequence_aa'` to toggle this behavior. Can also try `junction` or `junction_aa` if just want to visualise the CDR3 linkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, i'm removing the Orphan VJ cells (lacking TRB chain i.e. VDJ information).\n",
    "vdj = vdj[\n",
    "    vdj.metadata.chain_status.isin(\n",
    "        [\"Single pair\", \"Extra pair\", \"Extra pair-exception\", \"Orphan VDJ\"]\n",
    "    )\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.generate_network(vdj, key=\"sequence_aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Plotting in scanpy.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.transfer(\n",
    "    adata, vdj\n",
    ")  # this will include singletons. To show only expanded clones, specify expanded_only=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=[5, 5])\n",
    "ddl.pl.clone_network(adata, color=[\"sample_id\"], edges_width=1, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=[4.5, 5])\n",
    "ddl.pl.clone_network(\n",
    "    adata,\n",
    "    color=[\n",
    "        \"chain_status\",\n",
    "        \"rearrangement_status_VDJ\",\n",
    "        \"rearrangement_status_VJ\",\n",
    "    ],\n",
    "    ncols=1,\n",
    "    legend_fontoutline=3,\n",
    "    size=10,\n",
    "    edges_width=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.transfer(adata, vdj, expanded_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=[5, 5])\n",
    "ddl.pl.clone_network(adata, color=[\"sample_id\"], edges_width=1, size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=[4.5, 5])\n",
    "ddl.pl.clone_network(\n",
    "    adata,\n",
    "    color=[\n",
    "        \"locus_status\",\n",
    "        \"rearrangement_status_VDJ\",\n",
    "        \"rearrangement_status_VJ\",\n",
    "    ],\n",
    "    ncols=1,\n",
    "    legend_fontoutline=3,\n",
    "    edges_width=1,\n",
    "    size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `scirpy` to plot\n",
    "You can also use `scirpy`'s functions to plot the network. \n",
    "\n",
    "A likely use case is if you have a lot of cells and you don't want to wait for `dandelion` to generate the layout because it's taking too long. Or you simply prefer scirpy's style of plotting.\n",
    "\n",
    "You can run `ddl.tl.generate_network(..., compute_layout = False)` and it will finish ultra-fast, and after transfer to `scirpy`, you can use its plotting functions to visualise the networks - the clone network is generated very quickly but visualising it using spring layout does take quite a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scirpy as ir\n",
    "\n",
    "ir.tl.clonotype_network(adata, min_cells=2)\n",
    "ir.pl.clonotype_network(adata, color=\"clone_id\", panel_size=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the clonotype labels by transferring with a different `clone_key`. For example, from numerically ordered from largest to smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.transfer(adata, vdj, clone_key=\"clone_id_by_size\")\n",
    "ir.tl.clonotype_network(adata, clonotype_key=\"clone_id_by_size\", min_cells=2)\n",
    "ir.pl.clonotype_network(adata, color=\"clone_id_by_size\", panel_size=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also transfer with the clones collapsed for plotting as pie-charts as per how `scirpy` does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddl.tl.transfer(adata, vdj, clone_key=\"clone_id_by_size\", collapse_nodes=True)\n",
    "ir.tl.clonotype_network(adata, clonotype_key=\"clone_id_by_size\", min_cells=2)\n",
    "ir.pl.clonotype_network(adata, color=\"sample_id\", panel_size=(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Finish.</b>\n",
    "\n",
    "We can save the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"adata_tcr.h5ad\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj.write_h5ddl(\"dandelion_results_tcr.h5ddl\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
