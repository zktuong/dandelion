{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# V(D)J pseudobulk feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dandelion as ddl\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This notebook makes use of Milopy and Palantir, two packages that are not formally Dandelion's dependencies. V(D)J feature space applications are open-ended, this is just one of them. Be sure to install the packages beforehand if you want to follow along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import milopy.core as milo\n",
    "import palantir\n",
    "\n",
    "#required because of Palantir\n",
    "%matplotlib inline\n",
    "\n",
    "sc.settings.set_figure_params(dpi=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We've prepared a demo object based on the TCR trajectory shown in the manuscript for you to use here. It's had some analysis done on the GEX, and has Dandelion-derived contig information merged into it.\n",
    "\n",
    "It's possible to use VDJ information that comes from other sources than Dandelion processing, e.g. the pseudobulking will work with Scirpy output. The functions are just calibrated to work with Dandelion's structure by default. **An explicit Scirpy object example will be shown later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"demo-pseudobulk.h5ad\"):\n",
    "    os.system(\"wget ftp://ftp.sanger.ac.uk/pub/users/kp9/demo-pseudobulk.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Prior to performing the pseudobulking, it is recommended to run `ddl.tl.setup_vdj_pseudobulk()`. This will subset the object to just cells with at least a pair of chains, and prepare appropriately named and formatted columns for the pseudobulking function to use as defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"demo-pseudobulk.h5ad\")\n",
    "adata = ddl.tl.setup_vdj_pseudobulk(adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We're going to be using Milopy to create pseudobulks. Construct a neighbour graph with many neighbours, following Milopy protocol, and then sample representative neighbourhoods from the object. This saves a cell-by-pseudobulk matrix into `adata.obsm[\"nhoods\"]`. Use this graph to generate a UMAP as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep=\"X_scvi\", n_neighbors=50)\n",
    "milo.make_nhoods(adata)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now we are armed with everything we need to construct the VJ feature space. Pseudobulks can be defined either via passing a list of `.obs` metadata columns, the unique values of the combination of which will serve as individual pseudobulks (via `obs_to_bulk`), or via an explicit cell-by-pseudobulk matrix (via `pbs`). Milopy created one of those for us, so we can use that as input.\n",
    "\n",
    "The cell type annotation lives in `.obs[\"anno_lvl_2_final_clean\"]`. Let's tell the function that we want to take the most common value per pseudobulk with us to the new VJ feature space object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_adata = ddl.tl.vdj_pseudobulk(\n",
    "    adata, pbs=adata.obsm[\"nhoods\"], obs_to_take=\"anno_lvl_2_final_clean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The new object has pseudobulks as observations, and the unique encountered VJ genes as the features. We can see the per-pseudobulk annotation, and `.obsm[\"pbs\"]`. In our case it's just a copy of the `pbs` argument, but if we were to go for `obs_to_bulk` this would be a cells by pseudobulks matrix capturing the assignment of the original cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Now that we have our VJ feature space pseudobulk object, we can do things with it. Let's run a PCA on it. The development trajectory is very nicely captured in the first two PC dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(pb_adata)\n",
    "sc.pl.pca(pb_adata, color=\"anno_lvl_2_final_clean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Let's define the start of our trajectory as the right-most cell, the CD4 terminal state as the bottom-most cell, and the CD8 terminal state as the top-most cell. We can then follow Palantir protocol to generate a diffusion map and run pseudotime. Once done, we rename the terminal states to be more informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootcell = np.argmax(pb_adata.obsm[\"X_pca\"][:, 0])\n",
    "terminal_states = pd.Series(\n",
    "    [\"CD8+T\", \"CD4+T\"],\n",
    "    index=pb_adata.obs_names[\n",
    "        [\n",
    "            np.argmax(pb_adata.obsm[\"X_pca\"][:, 1]),\n",
    "            np.argmin(pb_adata.obsm[\"X_pca\"][:, 1]),\n",
    "        ]\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Run diffusion maps\n",
    "pca_projections = pd.DataFrame(pb_adata.obsm[\"X_pca\"], index=pb_adata.obs_names)\n",
    "dm_res = palantir.utils.run_diffusion_maps(pca_projections, n_components=5)\n",
    "ms_data = palantir.utils.determine_multiscale_space(dm_res)\n",
    "\n",
    "pr_res = palantir.core.run_palantir(\n",
    "    ms_data,\n",
    "    pb_adata.obs_names[rootcell],\n",
    "    num_waypoints=500,\n",
    "    terminal_states=terminal_states.index,\n",
    ")\n",
    "\n",
    "pr_res.branch_probs.columns = terminal_states[pr_res.branch_probs.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We can easily transfer the inferred pseudotime and branching probabilities to the pseudobulk object with the aid of a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_adata = ddl.tl.pseudotime_transfer(pb_adata, pr_res)\n",
    "sc.pl.pca(\n",
    "    pb_adata,\n",
    "    color=[\"pseudotime\", \"prob_CD4+T\", \"prob_CD8+T\"],\n",
    "    color_map=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We can project back our findings to the original cell space object via another helper function. This will remove any cells not in any of the pseudobulks. In the event of a cell belonging to multiple pseudobulks, the cell's pseudotime will be the average of the pseudobulks weighted by the inverse of the pseudobulk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata = ddl.tl.project_pseudotime_to_cell(\n",
    "    adata, pb_adata, terminal_states.values\n",
    ")\n",
    "sc.pl.umap(bdata, color=[\"anno_lvl_2_final_clean\"])\n",
    "sc.pl.umap(\n",
    "    bdata,\n",
    "    color=[\"pseudotime\", \"prob_CD4+T\", \"prob_CD8+T\"],\n",
    "    color_map=\"coolwarm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Pseudobulking on a Scirpy object\n",
    "\n",
    "It's possible to use the pseudobulking functions on a Scirpy object directly, but it will require some different arguments and minimal manual preprocessing beforehand. Let's grab a Scirpy object, availabe [here](https://cellgeni.cog.sanger.ac.uk/pan-immune/adata_TILC_TCR_onlyseq.h5ad), and see how we would go about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"adata_TILC_TCR_onlyseq.h5ad\"):\n",
    "    os.system(\n",
    "        \"wget https://cellgeni.cog.sanger.ac.uk/pan-immune/adata_TILC_TCR_onlyseq.h5ad\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Load the object and simplify its annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\"adata_TILC_TCR_onlyseq.h5ad\")\n",
    "\n",
    "# retain the following clusters\n",
    "ct_order = [\n",
    "    \"MAIT\",\n",
    "    \"Tem/emra_CD8\",\n",
    "    \"Tnaive/CM_CD8\",\n",
    "    \"Trm/em_CD8\",\n",
    "    \"Trm_gut_CD8\",\n",
    "    \"Teffector/EM_CD4\",\n",
    "    \"Tfh\",\n",
    "    \"Tnaive/CM_CD4\",\n",
    "    \"Tnaive/CM_CD4_activated\",\n",
    "    \"Tregs\",\n",
    "    \"Trm_Th1/Th17\",\n",
    "]\n",
    "adata = adata[adata.obs[\"manual_annot_v6\"].isin(ct_order)]\n",
    "\n",
    "# simplify the annotation to CD4, CD8 and MAIT\n",
    "translate = {\"MAIT\": \"MAIT\"}\n",
    "for clus in [\"Tem/emra_CD8\", \"Tnaive/CM_CD8\", \"Trm/em_CD8\", \"Trm_gut_CD8\"]:\n",
    "    translate[clus] = \"CD8+T\"\n",
    "for clus in [\n",
    "    \"Teffector/EM_CD4\",\n",
    "    \"Tfh\",\n",
    "    \"Tnaive/CM_CD4\",\n",
    "    \"Tnaive/CM_CD4_activated\",\n",
    "    \"Tregs\",\n",
    "    \"Trm_Th1/Th17\",\n",
    "]:\n",
    "    translate[clus] = \"CD4+T\"\n",
    "adata.obs[\"annot_high\"] = (\n",
    "    adata.obs[\"manual_annot_v6\"].astype(\"str\").map(translate)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "`ddl.tl.setup_vdj_pseudobulk()` subsets the object to cells with both chains present. We'll have to do this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[\n",
    "    adata.obs[\"chain_pairing\"].isin(\n",
    "        [\"single pair\", \"extra VJ\", \"extra VDJ\", \"two full chains\"]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "At this point, the Scirpy object can be fed into `ddl.tl.vdj_pseudobulk()`. The columns with the VDJ calls are named differently than in the Dandelion object, but this can be accounted for by specifying `extract_cols = ['IR_VDJ_1_v_gene', 'IR_VDJ_1_j_gene', 'IR_VJ_1_v_gene', 'IR_VJ_1_j_gene']`.\n",
    "\n",
    "For illustrative purposes, let's perform pseudobulking based on cell metadata rather than neighbourhoods - a combination of the original granular annotation and donor ID, present as columns in `.obs`. This would work just fine with a matrix of pseudobulk assignments like was done earlier with Milo for the Dandelion example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_adata = ddl.tl.vdj_pseudobulk(\n",
    "    adata,\n",
    "    obs_to_bulk=[\"donor_id\", \"manual_annot_v6\"],\n",
    "    obs_to_take=[\"donor_id\", \"manual_annot_v6\", \"annot_high\"],\n",
    "    extract_cols=[\n",
    "        \"IR_VDJ_1_v_gene\",\n",
    "        \"IR_VDJ_1_j_gene\",\n",
    "        \"IR_VJ_1_v_gene\",\n",
    "        \"IR_VJ_1_j_gene\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Let's make a UMAP of the pseudobulks. The object is operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(pb_adata)\n",
    "sc.pp.neighbors(pb_adata)\n",
    "sc.tl.umap(pb_adata)\n",
    "sc.pl.umap(pb_adata, color=\"annot_high\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
